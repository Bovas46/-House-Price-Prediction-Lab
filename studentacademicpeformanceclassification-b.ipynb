{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":561,"sourceType":"datasetVersion","datasetId":251}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.A(\"uciml/student-alcohol-consumption\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T02:56:22.764137Z","iopub.execute_input":"2025-06-27T02:56:22.764531Z","iopub.status.idle":"2025-06-27T02:56:22.775079Z","shell.execute_reply.started":"2025-06-27T02:56:22.764508Z","shell.execute_reply":"2025-06-27T02:56:22.773934Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3758461942.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Download latest version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uciml/student-alcohol-consumption\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path to dataset files:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'kagglehub' has no attribute 'A'"],"ename":"AttributeError","evalue":"module 'kagglehub' has no attribute 'A'","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":" Downloading Dataset Using kagglehub\n\nWe use the kagglehub library to directly download the Student Alcohol Consumption dataset from Kaggle.\n\nThis code will:\n\nAutomatically download the dataset to your Kaggle environment.\n\nPrint the file path where the dataset is saved, which you can then use to load it into a DataFrame.","metadata":{}},{"cell_type":"code","source":"# Import Libraries and Load Data\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Load data\ndf = pd.read_csv('/kaggle/input/student-alcohol-consumption/student-mat.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T02:56:30.435120Z","iopub.execute_input":"2025-06-27T02:56:30.435497Z","iopub.status.idle":"2025-06-27T02:56:32.400656Z","shell.execute_reply.started":"2025-06-27T02:56:30.435470Z","shell.execute_reply":"2025-06-27T02:56:32.399658Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n\n  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n0      4        3      4     1     1      3        6   5   6   6  \n1      5        3      3     1     1      3        4   5   5   6  \n2      4        3      2     2     3      3       10   7   8  10  \n3      3        2      2     1     1      5        2  15  14  15  \n4      4        3      2     1     2      5        4   6  10  10  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>school</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>address</th>\n      <th>famsize</th>\n      <th>Pstatus</th>\n      <th>Medu</th>\n      <th>Fedu</th>\n      <th>Mjob</th>\n      <th>Fjob</th>\n      <th>...</th>\n      <th>famrel</th>\n      <th>freetime</th>\n      <th>goout</th>\n      <th>Dalc</th>\n      <th>Walc</th>\n      <th>health</th>\n      <th>absences</th>\n      <th>G1</th>\n      <th>G2</th>\n      <th>G3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>18</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>A</td>\n      <td>4</td>\n      <td>4</td>\n      <td>at_home</td>\n      <td>teacher</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>17</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>1</td>\n      <td>1</td>\n      <td>at_home</td>\n      <td>other</td>\n      <td>...</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>15</td>\n      <td>U</td>\n      <td>LE3</td>\n      <td>T</td>\n      <td>1</td>\n      <td>1</td>\n      <td>at_home</td>\n      <td>other</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>15</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>4</td>\n      <td>2</td>\n      <td>health</td>\n      <td>services</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>15</td>\n      <td>14</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>16</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>3</td>\n      <td>3</td>\n      <td>other</td>\n      <td>other</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Importing Libraries & Loading the Data\n\nIn this step, we:\n\n- Import essential Python libraries for data analysis, visualization, and machine learning.\n- Load the Student Alcohol Consumption dataset using pandas.\n\nThe dataset student-mat.csv contains information about students’ academic performance and alcohol consumption. This will help us explore behavioral patterns and predict outcomes using classification models.\n\n\n- The dataset was successfully loaded and contains various student-related features such as demographics, academic performance, and alcohol consumption.\n- We verified that there are no missing values. ensuring data quality.\n- =Descriptive statistics** revealed useful insights into the range and distribution of numeric variables.\n- Visualizations helped us identify:\n  - The distribution of key variables (e.g., G1,G2,G3 for grades).\n  - Correlations between features using a heatmap, showing strong relationships between midterm (G1,G2) and final grades (G3).\n  - Differences in alcohol consumption patterns across gender, weekdays vs. weekends, and study time.\n- Based on the findings, we can now proceed with preprocessing and feature selection for modeling.\n\nThe insights from EDA will guide our machine learning pipeline and help improve model performance.\n","metadata":{}},{"cell_type":"code","source":"# Create the Target Variable\n# Create binary label\ndf['high_grade'] = (df['G3'] >= 10).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:04:20.903095Z","iopub.execute_input":"2025-06-27T00:04:20.903389Z","iopub.status.idle":"2025-06-27T00:04:20.910628Z","shell.execute_reply.started":"2025-06-27T00:04:20.903369Z","shell.execute_reply":"2025-06-27T00:04:20.909631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\nTo prepare the data for classification, we created a new binary target variable called high_grade:\n\n- Students with a final grade (G3) greater than or equal to 10 are labeled as 1 (high performance).\n- Students with a grade below 10 are labeled as 0 (low performance).\n\nThis transformation simplifies the task into a binary classification problem, allowing us to predict whether a student is likely to perform well or not based on other features.\n","metadata":{}},{"cell_type":"code","source":"# Preprocessing\n# Drop G1, G2, G3 since they directly influence the label\ndf = df.drop(['G1', 'G2', 'G3'], axis=1)\n\n# Encode categorical variables\ndf = pd.get_dummies(df, drop_first=True)\n\n# Train/test split\nX = df.drop('high_grade', axis=1)\ny = df['high_grade']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:06:03.118634Z","iopub.execute_input":"2025-06-27T00:06:03.118974Z","iopub.status.idle":"2025-06-27T00:06:03.151163Z","shell.execute_reply.started":"2025-06-27T00:06:03.118949Z","shell.execute_reply":"2025-06-27T00:06:03.150252Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\nBefore training our models, we performed the following preprocessing steps:\n\n- Dropped G1,G2, and G3: These are earlier and final grades that directly impact the target (`high_grade`), so we removed them to prevent data leakage.\n- Encoded categorical variables using one-hot encoding with drop_first=True to avoid multicollinearity and convert categorical features into numerical format.\n- Split the dataset into training and testing sets:\n  - 80% for training\n  - 20% for testing\n  - Used random_state=42 to ensure reproducibility\n\nThese steps ensure our data is clean, numeric, and ready for machine learning model training.\n","metadata":{}},{"cell_type":"code","source":"# Modeling\n# Train a few classifiers\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Decision Tree\": DecisionTreeClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(f\"\\n{name} Results:\")\n    print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:08:30.654511Z","iopub.execute_input":"2025-06-27T00:08:30.654975Z","iopub.status.idle":"2025-06-27T00:08:32.443391Z","shell.execute_reply.started":"2025-06-27T00:08:30.654935Z","shell.execute_reply":"2025-06-27T00:08:32.442571Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\nWe trained and evaluated three different classification models to predict whether a student will achieve a high grade:\n\n- Logistic Regression: A linear model suitable for binary classification problems.\n- Random Forest Classifier: An ensemble method using multiple decision trees for improved accuracy and robustness.\n- Decision Tree Classifier: A simple, interpretable tree-based model.\n\nEach model was:\n- Trained on the training set (X_train, y_train)\n- Evaluated on the test set (X_test, y_test)\n- Measured using the classification report, which includes:\n  - Precision\n  - Recall\n  - F1-Score\n  - Accuracy\n\nThese results provide insight into how well each model performs and help us compare their effectiveness for our prediction task.\n","metadata":{}},{"cell_type":"code","source":"# Hyperparameter Tuning\n# Tune Random Forest\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [5, 10, 15]\n}\ngrid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1')\ngrid.fit(X_train, y_train)\nprint(\"Best Params:\", grid.best_params_)\nprint(\"Best F1 Score:\", grid.best_score_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:10:38.606857Z","iopub.execute_input":"2025-06-27T00:10:38.607168Z","iopub.status.idle":"2025-06-27T00:10:46.934338Z","shell.execute_reply.started":"2025-06-27T00:10:38.607144Z","shell.execute_reply":"2025-06-27T00:10:46.933428Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Hyperparameter Tuning Summary\n\nTo improve the performance of our Random Forest Classifier, we used GridSearchCV to tune key hyperparameters:\n\n- n_estimators: Number of trees in the forest → tested values: 50, 100, 200\n- max_depth: Maximum depth of each tree → tested values: 5, 10, 15\n\nKey details:\n- Cross-validation: 5-fold (`cv=5`) to ensure reliable performance estimates\n- Scoring metric: F1 Score, which balances precision and recall\n\nThe grid search output provided:\n- The best combination of hyperparameters\n- The corresponding best F1 score, indicating the optimized model's performance\n\nThis step helps us build a more accurate and generalized model for predicting student performance.\n","metadata":{}},{"cell_type":"code","source":"Final Comparison & Reflection\n\nCompare models.Which one would you recommend for deployment in a school analytics tool and why?","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Final Comparison & Reflection\n\nModel Performance Comparison\n\nAfter training and evaluating three models — Logistic Regression, Decision Tree, and \nRandom Forest — we compared their results based on key classification metrics (Precision, Recall, F1-Score, and Accuracy):\n\n- Logistic Regression offered solid baseline performance with high interpretability, especially useful when transparency is important.\n- Decision Tree provided clear decision rules but tended to overfit on training data, showing slightly lower generalization performance.\n- Random Forest, especially after hyperparameter tuning, achieved the highest F1-score, indicating the best balance between precision and recall.\n\nRecommended Model\n\nRandom Forest Classifier is recommended for deployment in a school analytics tool due to the following reasons:\n\n- Strong performance across all evaluation metrics, especially after tuning.\n- Robustness to noise and overfitting thanks to ensemble learning.\n- Feature importance insights that can help educators understand key predictors of student success.\n- ]Scalability to work on larger or more complex datasets if extended in the future.\n\n Reflection\n\nBuilding this classification pipeline offered valuable hands-on experience with:\n\n- Real-world education-related data\n- End-to-end machine learning workflow\n- Trade-offs between interpretability and performance\n\nBy using such models, schools can better identify students at academic risk early and target interventions more effectively.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Assuming models dict and predictions from before, recompute metrics on test set\nmodel_metrics = {}\n\nfor name, model in models.items():\n    y_pred = model.predict(X_test)\n    model_metrics[name] = {\n        \"Accuracy\": accuracy_score(y_test, y_pred),\n        \"Precision\": precision_score(y_test, y_pred),\n        \"Recall\": recall_score(y_test, y_pred),\n        \"F1 Score\": f1_score(y_test, y_pred)\n    }\n\n# Create DataFrame for easy viewing\nmetrics_df = pd.DataFrame(model_metrics).T\nmetrics_df = metrics_df.round(3)\n\nprint(\"Evaluation Metrics Comparison:\")\nprint(metrics_df)\n\n# Plot F1 scores for visual comparison\nplt.figure(figsize=(8,5))\nmetrics_df[\"F1 Score\"].plot(kind='bar', color=['skyblue', 'lightgreen', 'salmon'])\nplt.title('Model Comparison: F1 Scores')\nplt.ylabel('F1 Score')\nplt.ylim(0, 1)\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T00:17:11.215993Z","iopub.execute_input":"2025-06-27T00:17:11.216321Z","iopub.status.idle":"2025-06-27T00:17:11.582844Z","shell.execute_reply.started":"2025-06-27T00:17:11.216296Z","shell.execute_reply":"2025-06-27T00:17:11.581844Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Recommended Model\n\nGiven its performance, robustness, and interpretability, Random Forest is the recommended choice for deployment in a school analytics tool. It can provide valuable insights into factors influencing student success while maintaining high predictive accuracy.\n\n Final Reflection\n\nThis project demonstrates the importance of:\n\n- Careful preprocessing and feature engineering\n- Model selection and hyperparameter tuning\n- Balancing interpretability with predictive performance\n\nDeploying such models can help educators identify students who may benefit from additional support early, improving academic outcomes.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}